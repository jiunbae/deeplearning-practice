{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Example\n",
    "\n",
    "- **Instructor**: Jongwoo Lim / Jiun Bae\n",
    "- **Email**: [jlim@hanyang.ac.kr](mailto:jlim@hanyang.ac.kr) / [jiunbae.623@gmail.com](mailto:jiunbae.623@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages\n",
    "\n",
    "First of all, Import some packages for using PyTorch.\n",
    "\n",
    "- torch.nn: The **Network** of PyTorch basically starts with nn.Module.\n",
    "- torch.nn.functional: for **Functions** such as *ReLU*, *MaxPool* (in this example)\n",
    "- torch.optim: for **Optimizers**\n",
    "- torchvision: Handling **Datasets**\n",
    "\n",
    "Numpy the basic scientific computing package used in customary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "PyTorch basically provides CIFAR-10 Dataset and support download in running code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "\t\t   'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '../data' # path to download cifar-10 dataset\n",
    "\n",
    "TRAIN_DATASET = datasets.CIFAR10(DATASET_DIR,   # Dataset root path\n",
    "                                 train=True,     # Train data\n",
    "                                 download=True)  # Download if not exist\n",
    "\n",
    "TEST_DATASET = datasets.CIFAR10(DATASET_DIR,    # Dataset root path\n",
    "                                train=False)     # Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network\n",
    "\n",
    "This is a simple convolution layer network includes 3 conv layer and 2 fc layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    \"\"\"Simple Neural Network contains conv layer and fc layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ConvNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(50*5*5, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 50*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train and Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion) -> float:\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion) -> Tuple[float, float, torch.Tensor]:\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, accuracy, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # 42, THE ANSWER TO LIFE, THE UNIVERSE AND EVERYTHING\n",
    "\n",
    "batch = 64            # batch size\n",
    "lr = .01              # learning rate\n",
    "epochs = 10\n",
    "\n",
    "TRAIN_DATASET.transform = transforms.ToTensor()\n",
    "train_loader = torch.utils.data.DataLoader(TRAIN_DATASET,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "TEST_DATASET.transform = transforms.ToTensor()\n",
    "test_loader = torch.utils.data.DataLoader(TEST_DATASET,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetwork().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    test_loss, accuracy, _ = test(model, device, test_loader, criterion)\n",
    "    \n",
    "    print('Epoch: {}\\t Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    print('\\t\\t Average Loss: {:.4f}, Accuracy: {:.0f}%'.format(test_loss, accuracy))\n",
    "\n",
    "torch.save(model.state_dict(), \"cifar_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetwork().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    test_loss, accuracy, _ = test(model, device, test_loader, criterion)\n",
    "    \n",
    "    print('Epoch: {}\\t Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    print('\\t\\t Average Loss: {:.4f}, Accuracy: {:.0f}%'.format(test_loss, accuracy))\n",
    "\n",
    "torch.save(model.state_dict(), \"cifar_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classwise accuracy\n",
    "\n",
    "Accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "def show(ary):\n",
    "    display(Image.fromarray(ary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = np.zeros(10)\n",
    "total = np.zeros(10)\n",
    "images = np.zeros((10, 3, 32, 32))\n",
    "\n",
    "for index, (image, label) in enumerate(TEST_DATASET):\n",
    "    total[label] += 1\n",
    "    \n",
    "    pred = model(image.to(device).unsqueeze(0))\n",
    "    pred = pred.argmax(dim=1).squeeze()\n",
    "    if label == pred:\n",
    "        if not correct[label]:\n",
    "            images[label] = np.array(image).copy()\n",
    "        correct[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (image, acc) in enumerate(zip(images, correct / total)):\n",
    "    show(np.transpose((image * 255).astype(np.uint8), (1, 2, 0)))\n",
    "    print(f'{CLASSES[index]}: {acc * 100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Change learning rate\n",
    "\n",
    "How does the learning rate affect the model's learning?\n",
    "\n",
    "- Change Adam optimizer learning rate 0.01 -> 0.001\n",
    "\n",
    "How can we define the learning rate?\n",
    "\n",
    "- There is no fixed answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetwork().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr*.1)\n",
    "criterion = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    test_loss, accuracy, _ = test(model, device, test_loader, criterion)\n",
    "    \n",
    "    print('Epoch: {}\\t Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    print('\\t\\t Average Loss: {:.4f}, Accuracy: {:.0f}%'.format(test_loss, accuracy))\n",
    "\n",
    "torch.save(model.state_dict(), \"cifar_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Change criterion\n",
    "\n",
    "Criterion(objective function) aka loss(or error) function is a function to be minimized(or maximized).\n",
    "\n",
    "The result of that function is called `loss`, `error`, `cost` or `penalty`.\n",
    "\n",
    "\n",
    "In this time we using `F.nll_loss`(*negative log-likelihood loss*).\n",
    "\n",
    "$$loss(x, class) = -log (\\frac{exp(x[class])} {\\sum_j exp(x[j])}) = -x[class] + log(\\sum_j exp(x[j]))$$\n",
    "\n",
    "We using categorical(one-hot encoded) label. So, using categorical loss.\n",
    "\n",
    "- Replace `F.nll_loss` to `F.cross_entropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetwork().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr*.1)\n",
    "criterion = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    test_loss, accuracy, _ = test(model, device, test_loader, criterion)\n",
    "    \n",
    "    print('Epoch: {}\\t Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    print('\\t\\t Average Loss: {:.4f}, Accuracy: {:.0f}%'.format(test_loss, accuracy))\n",
    "\n",
    "torch.save(model.state_dict(), \"cifar_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. VGG16 Network\n",
    "\n",
    "VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper `Very Deep Convolutional Networks for Large-Scale Image Recognition`.\n",
    "\n",
    "The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes. It was one of the famous model submitted to ILSVRC-2014.\n",
    "\n",
    "It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3Ã—3 kernel-sized filters one after another.\n",
    "\n",
    "![](../assets/vgg16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "criterion = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    test_loss, accuracy, _ = test(model, device, test_loader, criterion)\n",
    "    \n",
    "    print('Epoch: {}\\t Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    print('\\t\\t Average Loss: {:.4f}, Accuracy: {:.0f}%'.format(test_loss, accuracy))\n",
    "\n",
    "torch.save(model.state_dict(), \"cifar_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement VGG model code\n",
    "\n",
    "Write the model code by looking at the picture of the VGG16 given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
